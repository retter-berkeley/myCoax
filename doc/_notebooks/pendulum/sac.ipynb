{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box2d-py\n",
      "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
      "     ---------------------------------------- 0.0/374.5 kB ? eta -:--:--\n",
      "     -- ---------------------------------- 20.5/374.5 kB 320.0 kB/s eta 0:00:02\n",
      "     --- --------------------------------- 30.7/374.5 kB 435.7 kB/s eta 0:00:01\n",
      "     ---------- ------------------------- 112.6/374.5 kB 819.2 kB/s eta 0:00:01\n",
      "     -------------------------------------  368.6/374.5 kB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 374.5/374.5 kB 1.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py): started\n",
      "  Building wheel for box2d-py (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for box2d-py\n",
      "Failed to build box2d-py\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [16 lines of output]\n",
      "  Using setuptools (version 69.5.1).\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  creating build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "  copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "  running build_ext\n",
      "  building 'Box2D._Box2D' extension\n",
      "  swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "  swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "  error: command 'swig.exe' failed: None\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for box2d-py\n",
      "ERROR: Could not build wheels for box2d-py, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting box2d\n",
      "  Downloading Box2D-2.3.2.tar.gz (427 kB)\n",
      "     ---------------------------------------- 0.0/427.9 kB ? eta -:--:--\n",
      "     - ----------------------------------- 20.5/427.9 kB 330.3 kB/s eta 0:00:02\n",
      "     ----- ------------------------------- 61.4/427.9 kB 656.4 kB/s eta 0:00:01\n",
      "     ------------- ------------------------ 153.6/427.9 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 348.2/427.9 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 427.9/427.9 kB 2.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: box2d\n",
      "  Building wheel for box2d (setup.py): started\n",
      "  Building wheel for box2d (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for box2d\n",
      "Failed to build box2d\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [16 lines of output]\n",
      "  Using setuptools (version 69.5.1).\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  copying library\\Box2D\\Box2D.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  copying library\\Box2D\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\n",
      "  creating build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "  copying library\\Box2D\\b2\\__init__.py -> build\\lib.win-amd64-cpython-312\\Box2D\\b2\n",
      "  running build_ext\n",
      "  building 'Box2D._Box2D' extension\n",
      "  swigging Box2D\\Box2D.i to Box2D\\Box2D_wrap.cpp\n",
      "  swig.exe -python -c++ -IBox2D -small -O -includeall -ignoremissing -w201 -globals b2Globals -outdir library\\Box2D -keyword -w511 -D_SWIG_KWARGS -o Box2D\\Box2D_wrap.cpp Box2D\\Box2D.i\n",
      "  error: command 'swig.exe' failed: None\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for box2d\n",
      "ERROR: Could not build wheels for box2d, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mamba install -c conda-forge box2d-py\n",
    "!mamba install -c conda-forge gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yapf 0.40.2 requires importlib-metadata>=6.6.0, but you have importlib-metadata 4.13.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/coax-dev/coax.git@main --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7084), started 0:03:18 ago. (Use '!kill 7084' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-acfd22e033ac3cca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-acfd22e033ac3cca\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./data/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to fix rendering errors.\n",
    "import os\n",
    "os.environ['SDL_VIDEODRIVER'] = 'dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shutup in c:\\users\\robert\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shutup\n",
    "##At the top of the code\n",
    "import shutup;\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: coax in c:\\users\\robert\\anaconda3\\lib\\site-packages (0.1.13)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (10.3.0)\n",
      "Requirement already satisfied: gymnasium>=0.26.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (1.12.0)\n",
      "Requirement already satisfied: pandas>=1.3.5 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (2.2.2)\n",
      "Requirement already satisfied: dm-haiku>=0.0.8 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (0.0.13)\n",
      "Requirement already satisfied: chex>=0.1.5 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (0.1.87)\n",
      "Requirement already satisfied: optax>=0.1.3 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (0.2.3)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (2.18.0)\n",
      "Requirement already satisfied: tensorboardX>=2.5.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (2.6.2.2)\n",
      "Requirement already satisfied: lz4>=4.0.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (4.3.2)\n",
      "Requirement already satisfied: cloudpickle>=2.2.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (4.13.0)\n",
      "Requirement already satisfied: dm-control>=1.0.7 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from coax) (1.0.24)\n",
      "Requirement already satisfied: absl-py>=0.9.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (4.11.0)\n",
      "Requirement already satisfied: jax>=0.4.27 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (0.4.34)\n",
      "Requirement already satisfied: jaxlib>=0.4.27 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (0.4.34)\n",
      "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (0.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\robert\\anaconda3\\lib\\site-packages (from chex>=0.1.5->coax) (69.5.1)\n",
      "Requirement already satisfied: dm-env in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (1.6)\n",
      "Requirement already satisfied: dm-tree!=0.1.2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (0.1.8)\n",
      "Requirement already satisfied: glfw in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (2.7.0)\n",
      "Requirement already satisfied: labmaze in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (1.0.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (5.2.1)\n",
      "Requirement already satisfied: mujoco>=3.2.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (3.2.4)\n",
      "Requirement already satisfied: protobuf>=3.19.4 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (3.20.3)\n",
      "Requirement already satisfied: pyopengl>=3.1.4 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (3.1.7)\n",
      "Requirement already satisfied: pyparsing>=3.0.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (3.0.9)\n",
      "Requirement already satisfied: requests in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-control>=1.0.7->coax) (4.66.4)\n",
      "Requirement already satisfied: jmp>=0.0.2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-haiku>=0.0.8->coax) (0.0.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from dm-haiku>=0.0.8->coax) (0.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium>=0.26.0->gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (0.0.4)\n",
      "Requirement already satisfied: ale-py>=0.9 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (0.10.1)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (2.3.5)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (2.6.1)\n",
      "Requirement already satisfied: swig==4.* in c:\\users\\robert\\anaconda3\\lib\\site-packages (from gymnasium[accept-rom-license,atari,box2d]>=0.26.0->coax) (4.2.1.post0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from importlib-metadata<5.0.0->coax) (3.17.0)\n",
      "Requirement already satisfied: etils[epy] in c:\\users\\robert\\anaconda3\\lib\\site-packages (from optax>=0.1.3->coax) (1.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from pandas>=1.3.5->coax) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from pandas>=1.3.5->coax) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from pandas>=1.3.5->coax) (2023.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (1.67.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (23.2)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tensorboard>=2.9.1->coax) (3.0.3)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from jax>=0.4.27->chex>=0.1.5->coax) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\robert\\anaconda3\\lib\\site-packages (from jax>=0.4.27->chex>=0.1.5->coax) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->coax) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from requests->dm-control>=1.0.7->coax) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from requests->dm-control>=1.0.7->coax) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from requests->dm-control>=1.0.7->coax) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robert\\anaconda3\\lib\\site-packages (from requests->dm-control>=1.0.7->coax) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\robert\\anaconda3\\lib\\site-packages (from tqdm->dm-control>=1.0.7->coax) (0.4.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\robert\\anaconda3\\lib\\site-packages (from etils[epath]->mujoco>=3.2.1->dm-control>=1.0.7->coax) (2024.3.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\robert\\anaconda3\\lib\\site-packages (from etils[epath]->mujoco>=3.2.1->dm-control>=1.0.7->coax) (6.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gymnasium 1.0.0 does not provide the extra 'accept-rom-license'\n"
     ]
    }
   ],
   "source": [
    "pip install coax --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TrainMonitor:ep: 1,\tT: 201,\tG: -1.57e+03,\tavg_r: -7.87,\tavg_G: -1.57e+03,\tt: 200,\tdt: 3.871ms\n",
      "INFO:TrainMonitor:ep: 2,\tT: 402,\tG: -1.08e+03,\tavg_r: -5.4,\tavg_G: -1.33e+03,\tt: 200,\tdt: 1.803ms\n",
      "INFO:TrainMonitor:ep: 3,\tT: 603,\tG: -1.32e+03,\tavg_r: -6.62,\tavg_G: -1.33e+03,\tt: 200,\tdt: 2.141ms\n",
      "INFO:TrainMonitor:ep: 4,\tT: 804,\tG: -1.07e+03,\tavg_r: -5.33,\tavg_G: -1.26e+03,\tt: 200,\tdt: 1.836ms\n",
      "INFO:TrainMonitor:ep: 5,\tT: 1,005,\tG: -823,\tavg_r: -4.12,\tavg_G: -1.17e+03,\tt: 200,\tdt: 1.895ms\n",
      "INFO:TrainMonitor:ep: 6,\tT: 1,206,\tG: -1.54e+03,\tavg_r: -7.69,\tavg_G: -1.23e+03,\tt: 200,\tdt: 1.912ms\n",
      "INFO:TrainMonitor:ep: 7,\tT: 1,407,\tG: -894,\tavg_r: -4.47,\tavg_G: -1.19e+03,\tt: 200,\tdt: 3.071ms\n",
      "INFO:TrainMonitor:ep: 8,\tT: 1,608,\tG: -753,\tavg_r: -3.76,\tavg_G: -1.13e+03,\tt: 200,\tdt: 2.476ms\n",
      "INFO:TrainMonitor:ep: 9,\tT: 1,809,\tG: -973,\tavg_r: -4.86,\tavg_G: -1.11e+03,\tt: 200,\tdt: 2.415ms\n",
      "INFO:TrainMonitor:ep: 10,\tT: 2,010,\tG: -1.7e+03,\tavg_r: -8.52,\tavg_G: -1.17e+03,\tt: 200,\tdt: 2.183ms\n",
      "INFO:TrainMonitor:ep: 11,\tT: 2,211,\tG: -1.5e+03,\tavg_r: -7.52,\tavg_G: -1.21e+03,\tt: 200,\tdt: 2.109ms\n",
      "INFO:TrainMonitor:ep: 12,\tT: 2,412,\tG: -1.15e+03,\tavg_r: -5.77,\tavg_G: -1.2e+03,\tt: 200,\tdt: 1.852ms\n",
      "INFO:TrainMonitor:ep: 13,\tT: 2,613,\tG: -1.36e+03,\tavg_r: -6.78,\tavg_G: -1.22e+03,\tt: 200,\tdt: 2.008ms\n",
      "INFO:TrainMonitor:ep: 14,\tT: 2,814,\tG: -1.29e+03,\tavg_r: -6.45,\tavg_G: -1.22e+03,\tt: 200,\tdt: 2.674ms\n",
      "INFO:TrainMonitor:ep: 15,\tT: 3,015,\tG: -1.17e+03,\tavg_r: -5.83,\tavg_G: -1.22e+03,\tt: 200,\tdt: 2.563ms\n",
      "INFO:TrainMonitor:ep: 16,\tT: 3,216,\tG: -1.36e+03,\tavg_r: -6.82,\tavg_G: -1.23e+03,\tt: 200,\tdt: 2.447ms\n",
      "INFO:TrainMonitor:ep: 17,\tT: 3,417,\tG: -1.15e+03,\tavg_r: -5.74,\tavg_G: -1.22e+03,\tt: 200,\tdt: 2.431ms\n",
      "INFO:TrainMonitor:ep: 18,\tT: 3,618,\tG: -1.17e+03,\tavg_r: -5.83,\tavg_G: -1.22e+03,\tt: 200,\tdt: 2.569ms\n",
      "INFO:TrainMonitor:ep: 19,\tT: 3,819,\tG: -902,\tavg_r: -4.51,\tavg_G: -1.19e+03,\tt: 200,\tdt: 2.327ms\n",
      "INFO:TrainMonitor:ep: 20,\tT: 4,020,\tG: -1.24e+03,\tavg_r: -6.18,\tavg_G: -1.19e+03,\tt: 200,\tdt: 2.883ms\n",
      "INFO:TrainMonitor:ep: 21,\tT: 4,221,\tG: -1.08e+03,\tavg_r: -5.42,\tavg_G: -1.18e+03,\tt: 200,\tdt: 1.891ms\n",
      "INFO:TrainMonitor:ep: 22,\tT: 4,422,\tG: -1.56e+03,\tavg_r: -7.81,\tavg_G: -1.22e+03,\tt: 200,\tdt: 1.841ms\n",
      "INFO:TrainMonitor:ep: 23,\tT: 4,623,\tG: -1.71e+03,\tavg_r: -8.56,\tavg_G: -1.27e+03,\tt: 200,\tdt: 1.824ms\n",
      "INFO:TrainMonitor:ep: 24,\tT: 4,824,\tG: -1.44e+03,\tavg_r: -7.19,\tavg_G: -1.29e+03,\tt: 200,\tdt: 2.249ms\n",
      "INFO:TrainMonitor:ep: 25,\tT: 5,025,\tG: -1.11e+03,\tavg_r: -5.56,\tavg_G: -1.27e+03,\tt: 200,\tdt: 2.001ms\n",
      "INFO:TrainMonitor:ep: 26,\tT: 5,226,\tG: -1.16e+03,\tavg_r: -5.82,\tavg_G: -1.26e+03,\tt: 200,\tdt: 20.146ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 390\n",
      "INFO:TrainMonitor:ep: 27,\tT: 5,427,\tG: -1.13e+03,\tavg_r: -5.67,\tavg_G: -1.24e+03,\tt: 200,\tdt: 14.815ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 227\n",
      "INFO:TrainMonitor:ep: 28,\tT: 5,628,\tG: -1.75e+03,\tavg_r: -8.75,\tavg_G: -1.3e+03,\tt: 200,\tdt: 14.751ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 63.3\n",
      "INFO:TrainMonitor:ep: 29,\tT: 5,829,\tG: -1.07e+03,\tavg_r: -5.35,\tavg_G: -1.27e+03,\tt: 200,\tdt: 10.015ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 44.5\n",
      "INFO:TrainMonitor:ep: 30,\tT: 6,030,\tG: -1.07e+03,\tavg_r: -5.34,\tavg_G: -1.25e+03,\tt: 200,\tdt: 10.047ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 29.7\n",
      "INFO:TrainMonitor:ep: 31,\tT: 6,231,\tG: -1.45e+03,\tavg_r: -7.25,\tavg_G: -1.27e+03,\tt: 200,\tdt: 9.018ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 21\n",
      "INFO:TrainMonitor:ep: 32,\tT: 6,432,\tG: -1.49e+03,\tavg_r: -7.44,\tavg_G: -1.29e+03,\tt: 200,\tdt: 8.634ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 15.7\n",
      "INFO:TrainMonitor:ep: 33,\tT: 6,633,\tG: -890,\tavg_r: -4.45,\tavg_G: -1.25e+03,\tt: 200,\tdt: 8.952ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 13.2\n",
      "INFO:TrainMonitor:ep: 34,\tT: 6,834,\tG: -1.84e+03,\tavg_r: -9.21,\tavg_G: -1.31e+03,\tt: 200,\tdt: 9.856ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 11.3\n",
      "INFO:TrainMonitor:ep: 35,\tT: 7,035,\tG: -973,\tavg_r: -4.87,\tavg_G: -1.28e+03,\tt: 200,\tdt: 9.009ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 10.4\n",
      "INFO:TrainMonitor:ep: 36,\tT: 7,236,\tG: -1.07e+03,\tavg_r: -5.36,\tavg_G: -1.26e+03,\tt: 200,\tdt: 8.039ms,\tSoftClippedDoubleQLearning/EntropyRegularizer/entropy: 0.838,\tSoftClippedDoubleQLearning/loss: 9.29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 92\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# learn\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m:\n\u001b[1;32m---> 92\u001b[0m     transition_batch \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39msample(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# init metrics dict\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\coax\\experience_replay\\_simple.py:84\u001b[0m, in \u001b[0;36mSimpleReplayBuffer.sample\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     82\u001b[0m transitions \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage, batch_size)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_state \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mgetstate()\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mleaves: onp\u001b[38;5;241m.\u001b[39mconcatenate(leaves, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39mtransitions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\jax\\_src\\tree_util.py:344\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[0;32m    342\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m    343\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\jax\\_src\\tree_util.py:344\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    342\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m    343\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\coax\\experience_replay\\_simple.py:84\u001b[0m, in \u001b[0;36mSimpleReplayBuffer.sample.<locals>.<lambda>\u001b[1;34m(*leaves)\u001b[0m\n\u001b[0;32m     82\u001b[0m transitions \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage, batch_size)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_state \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mgetstate()\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39mleaves: onp\u001b[38;5;241m.\u001b[39mconcatenate(leaves, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39mtransitions)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import jax\n",
    "import coax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "from numpy import prod\n",
    "import optax\n",
    "import time\n",
    "\n",
    "\n",
    "# the name of this script\n",
    "name = 'sac'\n",
    "\n",
    "# the Pendulum MDP\n",
    "env = gymnasium.make('Pendulum-v1', render_mode='rgb_array')\n",
    "env = coax.wrappers.TrainMonitor(env, name=name, tensorboard_dir=f\"./data/tensorboard/{name}\")\n",
    "\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(prod(env.action_space.shape) * 2, w_init=jnp.zeros),\n",
    "        hk.Reshape((*env.action_space.shape, 2)),\n",
    "    ))\n",
    "    x = seq(S)\n",
    "    mu, logvar = x[..., 0], x[..., 1]\n",
    "    return {'mu': mu, 'logvar': logvar}\n",
    "\n",
    "\n",
    "def func_q(S, A, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "    ))\n",
    "    X = jnp.concatenate((S, A), axis=-1)\n",
    "    return seq(X)\n",
    "\n",
    "\n",
    "# main function approximators\n",
    "pi = coax.Policy(func_pi, env)\n",
    "q1 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "q2 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "\n",
    "# target network\n",
    "q1_targ = q1.copy()\n",
    "q2_targ = q2.copy()\n",
    "\n",
    "# experience tracer\n",
    "tracer = coax.reward_tracing.NStep(n=5, gamma=0.9, record_extra_info=True)\n",
    "buffer = coax.experience_replay.SimpleReplayBuffer(capacity=25000)\n",
    "alpha = 0.2\n",
    "policy_regularizer = coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                               beta=alpha / tracer.n,\n",
    "                                                               gamma=tracer.gamma,\n",
    "                                                               n=[tracer.n])\n",
    "\n",
    "# updaters (use current pi to update the q-functions and use sampled action in contrast to TD3)\n",
    "qlearning1 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q1, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "qlearning2 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q2, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "soft_pg = coax.policy_objectives.SoftPG(pi, [q1_targ, q2_targ], optimizer=optax.adam(\n",
    "    1e-3), regularizer=coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                                 beta=alpha / tracer.n,\n",
    "                                                                 gamma=tracer.gamma,\n",
    "                                                                 n=jnp.arange(tracer.n)))\n",
    "\n",
    "tracker=[0.,0.]\n",
    "# train\n",
    "while env.T < 1000000:\n",
    "    s, info = env.reset()\n",
    "    total_reward=0\n",
    "    for t in range(200):#(env.spec.max_episode_steps):\n",
    "        a = pi(s)\n",
    "        s_next, r, done, truncated, info = env.step(a)\n",
    "\n",
    "        # trace rewards and add transition to replay buffer\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            buffer.add(tracer.pop())\n",
    "\n",
    "        # learn\n",
    "        if len(buffer) >= 5000:\n",
    "            transition_batch = buffer.sample(batch_size=128)\n",
    "\n",
    "            # init metrics dict\n",
    "            metrics = {}\n",
    "\n",
    "            # flip a coin to decide which of the q-functions to update\n",
    "            qlearning = qlearning1 if jax.random.bernoulli(q1.rng) else qlearning2\n",
    "            metrics.update(qlearning.update(transition_batch))\n",
    "\n",
    "            # delayed policy updates\n",
    "            if env.T >= 7500 and env.T % 4 == 0:\n",
    "                metrics.update(soft_pg.update(transition_batch))\n",
    "\n",
    "            env.record_metrics(metrics)\n",
    "\n",
    "            # sync target networks\n",
    "            q1_targ.soft_update(q1, tau=0.001)\n",
    "            q2_targ.soft_update(q2, tau=0.001)\n",
    "        total_reward+=r\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "        s = s_next\n",
    "    tracker.append([time.time(), total_reward])\n",
    "    #generate an animated GIF to see what's going on\n",
    "    if env.period(name='generate_gif', T_period=10000) and env.T > 5000:\n",
    "        T = env.T - env.T % 10000  # round to 10000s\n",
    "        coax.utils.generate_gif(\n",
    "            env=env, policy=pi, filepath=f\"./data/gifs/{name}/T{T:08d}.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.32974733  3.43390969]\n",
      "-4.07472279580695 0.06928462414246762 -4.075311794428909\n",
      "-1.2129598986219927 0.6356023177237322 -1.369402067312904\n",
      "-1.142732370281445 0.821903913564001 -1.407609076846576\n",
      "-1.039497749408414 0.8899836888096514 -1.3684394533089115\n",
      "-1.2527706184502503 0.9649448749886004 -1.581313641950574\n",
      "-1.095127536155878 0.6273181021625407 -1.2620746102143312\n",
      "-0.9518194185083404 0.9685437516229232 -1.357953314461643\n",
      "-1.2902232803259364 0.6345273474838065 -1.4378112072869147\n",
      "-1.1976309284048685 0.7383146476388387 -1.4069215897092382\n",
      "-1.2062447261316822 0.8932422147529683 -1.5009690181803503\n",
      "-1.1522039752839217 1.0037566554183939 -1.528103865565686\n",
      "-1.2867808910392395 0.6774050716171429 -1.4541948606003137\n",
      "-0.9859760618639 0.6238616479235849 -1.1667699646110952\n",
      "-1.258166827913797 0.5617628654920443 -1.3778828992002545\n",
      "-0.9420032333360431 0.7746057043224867 -1.219583571873816\n",
      "-1.038646076789013 0.6009681329322899 -1.1999784871527202\n",
      "-1.3939595046604842 0.5450062749902251 -1.4967147157731908\n",
      "-1.0578249896976608 1.4490223914858023 -1.7940623177181136\n",
      "-1.5673908997546404 0.5043372049540688 -1.6465327961916043\n",
      "-0.8172613019961977 0.7063566068925513 -1.0802109478436508\n",
      "-1.1254822831081293 0.7231385035640822 -1.3377741457089039\n",
      "-1.1890501835210028 0.8721730345752413 -1.4746274584353554\n",
      "-1.0060682019327276 1.0871001047451645 -1.481202168738994\n",
      "-1.2555678025420125 0.5755299551256772 -1.3811897900097372\n",
      "-0.9873795101761446 0.7270006887410361 -1.2261518252425447\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.33225347  0.54605892]\n"
     ]
    }
   ],
   "source": [
    "#display for van der pol\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import gymnasium\n",
    "\n",
    "env = gymnasium.make(\"VDP-v0\")\n",
    "observation, info = env.reset()\n",
    "s=observation\n",
    "#s=np.array([5.5,5.5])\n",
    "x=s[0]\n",
    "y=s[1]\n",
    "print(s)\n",
    "plt.figure(1)\n",
    "plt.scatter(x,y)#,'ro')\n",
    "for i in range(1000):\n",
    "    a= pi(s)\n",
    "    #a=np.array([0])\n",
    "    obs, reward, terminated, truncated, info = env.step(a)\n",
    "    s=obs\n",
    "    x=s[0]\n",
    "    y=s[1]\n",
    "    if i % 20 ==0:  \n",
    "        print(x,y,reward)\n",
    "        plt.scatter(x, y)\n",
    "    #print(reward)\n",
    "    if (terminated or truncated):  break\n",
    "env.close()\n",
    "plt.show()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:192: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` should be `(obs, info)` by default, , where `obs` is a observation and `info` is a dictionary containing additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\coax\\utils\\_array.py:335: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  X = jnp.asarray(X, dtype=space.dtype)   # ensure ndarray\n",
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\coax\\utils\\_array.py:335: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  X = jnp.asarray(X, dtype=space.dtype)   # ensure ndarray\n",
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\coax\\proba_dists\\_normal.py:185: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  X = jnp.asarray(X, dtype=self.space.dtype)                     # ensure ndarray\n",
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\coax\\utils\\_array.py:335: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  X = jnp.asarray(X, dtype=space.dtype)   # ensure ndarray\n",
      "C:\\Users\\Robert\\anaconda3\\Lib\\site-packages\\coax\\proba_dists\\_normal.py:192: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  X = jnp.asarray(X, dtype=self.space.dtype)                    # ensure ndarray\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 161\u001b[0m\n\u001b[0;32m    159\u001b[0m     start\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mfloor(control_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    160\u001b[0m     right_bound[control_points[i]\u001b[38;5;241m-\u001b[39mstart:control_points[i]\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;241m+\u001b[39mcontrol_size]\u001b[38;5;241m=\u001b[39ma[i]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 161\u001b[0m     top_bound[control_points[i]\u001b[38;5;241m-\u001b[39mstart:control_points[i]\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;241m+\u001b[39mcontrol_size]\u001b[38;5;241m=\u001b[39ma[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    162\u001b[0m all_bound\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mvstack([left_bound, right_bound])\n\u001b[0;32m    163\u001b[0m all_bound\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mvstack([all_bound, bottom_bound])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#SAC for PDE\n",
    "import gymnasium\n",
    "import jax\n",
    "import coax\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "from numpy import prod\n",
    "import optax\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "class controller:\n",
    "    def __init__(self, grid, state, num_sens):\n",
    "        self.grid=grid\n",
    "        self.num_sens=num_sens\n",
    "        self.state=state\n",
    "        self.control=[]\n",
    "\n",
    "#need function to reduce full space to just sensors \n",
    "def sensor_meas(sensors,domain):\n",
    "    #assume senors form a square grid, so take square root of number of sensors\n",
    "    #assume sensors read from middle of domain\n",
    "    n_sense=int(np.sqrt(sensors))\n",
    "    meas=np.empty((n_sense,n_sense))\n",
    "    dimx=domain.shape[0]\n",
    "    dimy=domain.shape[1]\n",
    "    startx=round((dimx-n_sense)/2)\n",
    "    starty=round((dimy-n_sense)/2)\n",
    "    for i in range(n_sense):\n",
    "        for j in range(n_sense):\n",
    "            meas[i,j]=float(domain[i+startx,j+starty])\n",
    "    return meas.flatten()\n",
    "\n",
    "# the name of this script\n",
    "name = 'sac'\n",
    "\n",
    "# the Pendulum MDP\n",
    "env = gymnasium.make('Diffusion-v0')\n",
    "obs, grid, state = env.reset(seed=random.randint(0,10000))\n",
    "env = coax.wrappers.TrainMonitor(env, name=name, tensorboard_dir=f\"./data/tensorboard/{name}\")\n",
    "\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(prod(env.action_space.shape) * 2, w_init=jnp.zeros),\n",
    "        hk.Reshape((*env.action_space.shape, 2)),\n",
    "    ))\n",
    "    x = seq(S)\n",
    "    mu, logvar = x[..., 0], x[..., 1]\n",
    "    return {'mu': mu, 'logvar': logvar}\n",
    "\n",
    "\n",
    "def func_q(S, A, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "    ))\n",
    "    X = jnp.concatenate((S, A), axis=-1)\n",
    "    return seq(X)\n",
    "\n",
    "\n",
    "# main function approximators\n",
    "pi = coax.Policy(func_pi, env)\n",
    "q1 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "q2 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "\n",
    "# target network\n",
    "q1_targ = q1.copy()\n",
    "q2_targ = q2.copy()\n",
    "\n",
    "# experience tracer\n",
    "tracer = coax.reward_tracing.NStep(n=5, gamma=0.9, record_extra_info=True)\n",
    "buffer = coax.experience_replay.SimpleReplayBuffer(capacity=25000)\n",
    "alpha = 0.2\n",
    "policy_regularizer = coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                               beta=alpha / tracer.n,\n",
    "                                                               gamma=tracer.gamma,\n",
    "                                                               n=[tracer.n])\n",
    "\n",
    "# updaters (use current pi to update the q-functions and use sampled action in contrast to TD3)\n",
    "qlearning1 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q1, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "qlearning2 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q2, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "soft_pg = coax.policy_objectives.SoftPG(pi, [q1_targ, q2_targ], optimizer=optax.adam(\n",
    "    1e-3), regularizer=coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                                 beta=alpha / tracer.n,\n",
    "                                                                 gamma=tracer.gamma,\n",
    "                                                                 n=jnp.arange(tracer.n)))\n",
    "\n",
    "tracker=[0.,0.]\n",
    "\n",
    "#insert controller parameters\n",
    "# number of controls, control locations.  Assume control is on boundary\n",
    "#here, with two control locations and 4 controls, that means that two boundaries have controls.\n",
    "#In gymanisum this will be hard coded as bottom and right side, or (x,ymin) and (xmax, y)\n",
    "num_sens=4*4\n",
    "num_control = 4\n",
    "control_size = 3 #number of grid points comprising controller\n",
    "control_points = np.array([8,20]) #grid x/y locations of controllers\n",
    "dx=1.\n",
    "dy=1.\n",
    "xmax=grid.shape[0]*dx\n",
    "ymax=grid.shape[1]*dy \n",
    "\n",
    "\n",
    "\n",
    "#hard code control locations\n",
    "control_loc=np.array([xmax, dy*control_points[0]]) #right side, 1st control point\n",
    "control_loc=np.vstack([control_loc,[xmax, dy*control_points[1]]]) #right side, 2nd control point\n",
    "control_loc=np.vstack([control_loc,[ymax, dx*control_points[0]]]) #top, 1st control point\n",
    "control_loc=np.vstack([control_loc,[ymax, dx*control_points[1]]]) #top 2nd control point\n",
    "\n",
    "#insert controller class initialization\n",
    "actor=controller(grid,state, num_sens)\n",
    "\n",
    "# train\n",
    "while env.T < 100000:\n",
    "    #modify for grid and state\n",
    "    obs, grid, state = env.reset()\n",
    "    actor=controller(grid, state, num_sens)\n",
    "    #insert sensor measurement and conversion here\n",
    "    s=sensor_meas(num_sens,state.data)\n",
    "    #add x,y coordinates to make nn input vector s.  This means that must add x,y for all control points to s\n",
    "    #i.e s dimension = #observation point measurements + 2*number of control points\n",
    "    #x and y locations are control loc variables, so s will need to append each element of control loc into s\n",
    "    for i in control_loc:\n",
    "        for j in i:\n",
    "            np.append(s, float(j.item()))\n",
    "    \n",
    "    total_reward=0\n",
    "    for t in range(200):#(env.spec.max_episode_steps):\n",
    "        #insert sensor measurement and conversion here\n",
    "        s=sensor_meas(num_sens,state.data)\n",
    "        #add x,y coordinates to make nn input vector s.  This means that must add x,y for all control points to s\n",
    "        #i.e s dimension = #observation point measurements + 2*number of control points\n",
    "        #x and y locations are control loc variables, so s will need to append each element of control loc into s\n",
    "        for i in control_loc:\n",
    "            for j in i:\n",
    "                np.append(s, float(j.item()))\n",
    "        a = pi(s)\n",
    "        #insert boundary condition defnitiions\n",
    "        left_bound=np.zeros(grid.shape[1])\n",
    "        right_bound=np.zeros(grid.shape[1])\n",
    "        bottom_bound=np.zeros(grid.shape[0])\n",
    "        top_bound=np.zeros(grid.shape[0])\n",
    "        for i in range(len(control_points)):\n",
    "            start=math.floor(control_size/2)\n",
    "            right_bound[control_points[i]-start:control_points[i]-start+control_size]=a[i].item()\n",
    "            top_bound[control_points[i]-start:control_points[i]-start+control_size]=a[i+2].item()\n",
    "        all_bound=np.vstack([left_bound, right_bound])\n",
    "        all_bound=np.vstack([all_bound, bottom_bound])\n",
    "        all_bound=np.vstack([all_bound, top_bound])\n",
    "        #add boundary conditions to controller class instance\n",
    "        actor.control=all_bound\n",
    "        \n",
    "        s_next, r, done, truncated, info = env.step(actor)\n",
    "        implement.state.data=s_next\n",
    "        # trace rewards and add transition to replay buffer\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            buffer.add(tracer.pop())\n",
    "\n",
    "        # learn\n",
    "        if len(buffer) >= 5000:\n",
    "            transition_batch = buffer.sample(batch_size=128)\n",
    "\n",
    "            # init metrics dict\n",
    "            metrics = {}\n",
    "\n",
    "            # flip a coin to decide which of the q-functions to update\n",
    "            qlearning = qlearning1 if jax.random.bernoulli(q1.rng) else qlearning2\n",
    "            metrics.update(qlearning.update(transition_batch))\n",
    "\n",
    "            # delayed policy updates\n",
    "            if env.T >= 7500 and env.T % 4 == 0:\n",
    "                metrics.update(soft_pg.update(transition_batch))\n",
    "\n",
    "            env.record_metrics(metrics)\n",
    "\n",
    "            # sync target networks\n",
    "            q1_targ.soft_update(q1, tau=0.001)\n",
    "            q2_targ.soft_update(q2, tau=0.001)\n",
    "        total_reward+=r\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "        s = s_next\n",
    "    tracker.append([time.time(), total_reward])\n",
    "    #generate an animated GIF to see what's going on\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 161\u001b[0m\n\u001b[0;32m    157\u001b[0m     left_control[j]\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    159\u001b[0m actor\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m=\u001b[39mleft_control\n\u001b[1;32m--> 161\u001b[0m s_next, r, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actor)\n\u001b[0;32m    162\u001b[0m actor\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39ms_next\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#if t % 10 ==0:  print(time.time()-start)\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# trace rewards and add transition to replay buffer\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[0;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gymnasium\\core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\Diffusion.py:79\u001b[0m, in \u001b[0;36mDiffusionEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     76\u001b[0m bc_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperiodic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m eq \u001b[38;5;241m=\u001b[39m DiffusionPDE(diffusivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, bc\u001b[38;5;241m=\u001b[39m[bc_x, bc_y])\n\u001b[1;32m---> 79\u001b[0m result \u001b[38;5;241m=\u001b[39m eq\u001b[38;5;241m.\u001b[39msolve(action\u001b[38;5;241m.\u001b[39mstate, t_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, adaptive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, tracker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdata       \n\u001b[0;32m     81\u001b[0m done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\pdes\\base.py:644\u001b[0m, in \u001b[0;36mPDEBase.solve\u001b[1;34m(self, state, t_range, dt, tracker, solver, ret_info, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# run the simulation\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     final_state \u001b[38;5;241m=\u001b[39m controller\u001b[38;5;241m.\u001b[39mrun(state, dt)\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;66;03m# copy diagnostic information to the PDE instance\u001b[39;00m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiagnostics\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\controller.py:332\u001b[0m, in \u001b[0;36mController.run\u001b[1;34m(self, initial_state, dt)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# decide whether to call the main routine or whether this is an MPI client\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mpi\u001b[38;5;241m.\u001b[39mis_main:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# this node is the primary one\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single(state, dt)\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m mpi\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# multiple processes are used and this is one of the secondaries\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\controller.py:179\u001b[0m, in \u001b[0;36mController._run_single\u001b[1;34m(self, state, dt)\u001b[0m\n\u001b[0;32m    176\u001b[0m handle_stop_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_stop_handler()\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# initialize the stepper\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m stepper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mmake_stepper(state\u001b[38;5;241m=\u001b[39mstate, dt\u001b[38;5;241m=\u001b[39mdt)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# store intermediate profiling information before starting simulation\u001b[39;00m\n\u001b[0;32m    182\u001b[0m jit_count_after_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(JIT_COUNT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\base.py:648\u001b[0m, in \u001b[0;36mAdaptiveSolverBase.make_stepper\u001b[1;34m(self, state, dt)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# create stepper with adaptive steps\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt_statistics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OnlineStatistics()\n\u001b[1;32m--> 648\u001b[0m adaptive_stepper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_adaptive_stepper(state)\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dt_float\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt_adaptive\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\explicit.py:390\u001b[0m, in \u001b[0;36mExplicitSolver._make_adaptive_stepper\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheme\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheme\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuler\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_adaptive_euler_stepper(state)\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunge-kutta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrk45\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_make_adaptive_stepper(state)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\explicit.py:181\u001b[0m, in \u001b[0;36mExplicitSolver._make_adaptive_euler_stepper\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use adaptive stepper with stochastic equation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# obtain functions determining how the PDE is evolved\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m rhs_pde \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_pde_rhs(state, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend)\n\u001b[0;32m    182\u001b[0m post_step_hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_post_step_hook(state)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# obtain auxiliary functions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\solvers\\base.py:223\u001b[0m, in \u001b[0;36mSolverBase._make_pde_rhs\u001b[1;34m(self, state, backend)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_sde\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot create a deterministic stepper for a stochastic equation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 223\u001b[0m rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpde\u001b[38;5;241m.\u001b[39mmake_pde_rhs(state, backend\u001b[38;5;241m=\u001b[39mbackend)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(rhs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m rhs\u001b[38;5;241m.\u001b[39m_backend\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\pdes\\base.py:295\u001b[0m, in \u001b[0;36mPDEBase.make_pde_rhs\u001b[1;34m(self, state, backend, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m         rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_pde_rhs_numba_cached(state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m         backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\pdes\\base.py:264\u001b[0m, in \u001b[0;36mPDEBase._make_pde_rhs_numba_cached\u001b[1;34m(self, state, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m     rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpde_rhs_numba\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# caching was skipped\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     rhs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_pde_rhs_numba(state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rhs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`_make_pde_rhs_numba` returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\pdes\\diffusion.py:112\u001b[0m, in \u001b[0;36mDiffusionPDE._make_pde_rhs_numba\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    109\u001b[0m diffusivity_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusivity\n\u001b[0;32m    110\u001b[0m laplace \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39mmake_operator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaplace\u001b[39m\u001b[38;5;124m\"\u001b[39m, bc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbc)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;129m@jit\u001b[39m(signature)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpde_rhs\u001b[39m(state_data: np\u001b[38;5;241m.\u001b[39mndarray, t: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m    114\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compiled helper function evaluating right hand side.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m diffusivity_value \u001b[38;5;241m*\u001b[39m laplace(state_data, args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m: t})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\tools\\misc.py:124\u001b[0m, in \u001b[0;36mdecorator_arguments.<locals>.new_decorator.<locals>.<lambda>\u001b[1;34m(realf)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decorator(args[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# decorator arguments\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m realf: decorator(realf, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pde\\tools\\numba.py:203\u001b[0m, in \u001b[0;36mjit\u001b[1;34m(function, signature, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# increase the compilation counter by one\u001b[39;00m\n\u001b[0;32m    201\u001b[0m JIT_COUNT\u001b[38;5;241m.\u001b[39mincrement()\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nb\u001b[38;5;241m.\u001b[39mjit(signature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)(function)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\decorators.py:236\u001b[0m, in \u001b[0;36m_jit.<locals>.wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m typeinfer\u001b[38;5;241m.\u001b[39mregister_dispatcher(disp):\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m sigs:\n\u001b[1;32m--> 236\u001b[0m             disp\u001b[38;5;241m.\u001b[39mcompile(sig)\n\u001b[0;32m    237\u001b[0m         disp\u001b[38;5;241m.\u001b[39mdisable_compile()\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:957\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ev\u001b[38;5;241m.\u001b[39mtrigger_event(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumba:compile\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mev_details):\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 957\u001b[0m         cres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiler\u001b[38;5;241m.\u001b[39mcompile(args, return_type)\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mForceLiteralArg \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfolded\u001b[39m(args, kws):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:125\u001b[0m, in \u001b[0;36m_FunctionCompiler.compile\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, return_type):\n\u001b[1;32m--> 125\u001b[0m     status, retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_cached(args, return_type)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status:\n\u001b[0;32m    127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:139\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_cached\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_core(args, return_type)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mTypingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_failed_cache[key] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\dispatcher.py:152\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_core\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    149\u001b[0m flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_customize_flags(flags)\n\u001b[0;32m    151\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_implementation(args, {})\n\u001b[1;32m--> 152\u001b[0m cres \u001b[38;5;241m=\u001b[39m compiler\u001b[38;5;241m.\u001b[39mcompile_extra(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetdescr\u001b[38;5;241m.\u001b[39mtyping_context,\n\u001b[0;32m    153\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetdescr\u001b[38;5;241m.\u001b[39mtarget_context,\n\u001b[0;32m    154\u001b[0m                               impl,\n\u001b[0;32m    155\u001b[0m                               args\u001b[38;5;241m=\u001b[39margs, return_type\u001b[38;5;241m=\u001b[39mreturn_type,\n\u001b[0;32m    156\u001b[0m                               flags\u001b[38;5;241m=\u001b[39mflags, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocals,\n\u001b[0;32m    157\u001b[0m                               pipeline_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_class)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Check typing error if object mode is used\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cres\u001b[38;5;241m.\u001b[39mtyping_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m flags\u001b[38;5;241m.\u001b[39menable_pyobject:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler.py:751\u001b[0m, in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \n\u001b[0;32m    729\u001b[0m \u001b[38;5;124;03mParameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;124;03m    compiler pipeline\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    749\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    750\u001b[0m                           args, return_type, flags, \u001b[38;5;28mlocals\u001b[39m)\n\u001b[1;32m--> 751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39mcompile_extra(func)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler.py:445\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlifted_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_bytecode()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler.py:513\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfunc_ir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_core()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler.py:479\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 479\u001b[0m     pm\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    354\u001b[0m pass_inst \u001b[38;5;241m=\u001b[39m _pass_registry\u001b[38;5;241m.\u001b[39mget(pss)\u001b[38;5;241m.\u001b[39mpass_inst\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runPass(idx, pass_inst, state)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLegacy pass in use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[1;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[0;32m    309\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_initialization, internal_state)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m pass_time:\n\u001b[1;32m--> 311\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_pass, internal_state)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SimpleTimer() \u001b[38;5;28;01mas\u001b[39;00m finalize_time:\n\u001b[0;32m    313\u001b[0m     mutated \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m check(pss\u001b[38;5;241m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[1;34m(func, compiler_state)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(func, compiler_state):\n\u001b[1;32m--> 273\u001b[0m     mangled \u001b[38;5;241m=\u001b[39m func(compiler_state)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mangled \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass implementations should return True/False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompilerPass with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m did not.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\typed_passes.py:497\u001b[0m, in \u001b[0;36mBaseNativeLowering.run_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    491\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _LowerResult(fndesc, call_helper,\n\u001b[0;32m    492\u001b[0m                                cfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, env\u001b[38;5;241m=\u001b[39menv)\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;66;03m# Prepare for execution\u001b[39;00m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# Insert native function for use by other jitted-functions.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;66;03m# We also register its library to allow for inlining.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     cfunc \u001b[38;5;241m=\u001b[39m targetctx\u001b[38;5;241m.\u001b[39mget_executable(library, fndesc, env)\n\u001b[0;32m    498\u001b[0m     targetctx\u001b[38;5;241m.\u001b[39minsert_user_function(cfunc, fndesc, [library])\n\u001b[0;32m    499\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _LowerResult(fndesc, call_helper,\n\u001b[0;32m    500\u001b[0m                                cfunc\u001b[38;5;241m=\u001b[39mcfunc, env\u001b[38;5;241m=\u001b[39menv)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\cpu.py:239\u001b[0m, in \u001b[0;36mCPUContext.get_executable\u001b[1;34m(self, library, fndesc, env)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m-------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    an execution environment (from _dynfunc)\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Code generation\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m fnptr \u001b[38;5;241m=\u001b[39m library\u001b[38;5;241m.\u001b[39mget_pointer_to_function(\n\u001b[0;32m    240\u001b[0m     fndesc\u001b[38;5;241m.\u001b[39mllvm_cpython_wrapper_name)\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Note: we avoid reusing the original docstring to avoid encoding\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# issues on Python 2, see issue #1908\u001b[39;00m\n\u001b[0;32m    244\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled wrapper for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (fndesc\u001b[38;5;241m.\u001b[39mqualname,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\codegen.py:989\u001b[0m, in \u001b[0;36mJITCodeLibrary.get_pointer_to_function\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pointer_to_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    976\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    Generate native code for function named *name* and return a pointer\u001b[39;00m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m    to the start of the function (as an integer).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m        - non-zero if the symbol is defined.\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_finalized()\n\u001b[0;32m    990\u001b[0m     ee \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codegen\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ee\u001b[38;5;241m.\u001b[39mis_symbol_defined(name):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\codegen.py:567\u001b[0m, in \u001b[0;36mCodeLibrary._ensure_finalized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_finalized\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalized:\n\u001b[1;32m--> 567\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\codegen.py:762\u001b[0m, in \u001b[0;36mCPUCodeLibrary.finalize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_module\u001b[38;5;241m.\u001b[39mlink_in(\n\u001b[0;32m    757\u001b[0m             library\u001b[38;5;241m.\u001b[39m_get_module_for_linking(), preserve\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    758\u001b[0m         )\n\u001b[0;32m    760\u001b[0m \u001b[38;5;66;03m# Optimize the module after all dependences are linked in above,\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;66;03m# to allow for inlining.\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_final_module()\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_module\u001b[38;5;241m.\u001b[39mverify()\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_final_module()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numba\\core\\codegen.py:682\u001b[0m, in \u001b[0;36mCPUCodeLibrary._optimize_final_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m full_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule passes (full optimization)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recorded_timings\u001b[38;5;241m.\u001b[39mrecord(full_name):\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;66;03m# The full optimisation suite is then run on the refop pruned IR\u001b[39;00m\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codegen\u001b[38;5;241m.\u001b[39m_mpm_full\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_module)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llvmlite\\binding\\passmanagers.py:693\u001b[0m, in \u001b[0;36mModulePassManager.run\u001b[1;34m(self, module, remarks_file, remarks_format, remarks_filter)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03mRun optimization passes on the given module.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    The filter that should be applied to the remarks output.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remarks_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ffi\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mLLVMPY_RunPassManager(\u001b[38;5;28mself\u001b[39m, module)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     r \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mLLVMPY_RunPassManagerWithRemarks(\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28mself\u001b[39m, module, _encode_string(remarks_format),\n\u001b[0;32m    697\u001b[0m         _encode_string(remarks_filter),\n\u001b[0;32m    698\u001b[0m         _encode_string(remarks_file))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llvmlite\\binding\\ffi.py:192\u001b[0m, in \u001b[0;36m_lib_fn_wrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#implement diffusion PDE with gymnasium, interior control\n",
    "#review diffusion gym to make sure set up for interior control and periodic boundary\n",
    "#I use the gym to define the action space, but reset and step are replaced with direct calls to pde functions\n",
    "\n",
    "import gymnasium\n",
    "import jax\n",
    "import coax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "from numpy import prod\n",
    "import optax\n",
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pde\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import shutup;\n",
    "shutup.please()\n",
    "\n",
    "#geting warning about jax numpy converting float 62 to float 32.  The suggested fix doesn't work, so ignoring\n",
    "class controller:\n",
    "    def __init__(self, grid, state, num_sens):\n",
    "        self.grid=grid\n",
    "        self.num_sens=num_sens\n",
    "        self.state=state\n",
    "        self.control=[]\n",
    "\n",
    "from pde import DiffusionPDE, ScalarField, UnitGrid\n",
    "\n",
    "# the name of this script\n",
    "name = 'sac_Diffusion'\n",
    "\n",
    "#define number of sensors and inputs\n",
    "Num_sens=3*3 #size of observation/sensor space in number of grid points\n",
    "grid_dim=2 #x,y for including boundary location in alogrithim\n",
    "Ns=Num_sens+grid_dim #sensors are first in s array, then x,y are last 2 elements\n",
    "\n",
    "#to more easile use existing code for defining and using nns, use gym to define environment\n",
    "#with 1 action space, and Ns dimension observation space, which will help initialize actor\n",
    "env = gymnasium.make('Diffusion-v0', Ns)\n",
    "observation, grid, state0 = env.reset(seed=412)\n",
    "\n",
    "#need function to reduce full space to just sensors \n",
    "def sensor_meas(sensors,domain):\n",
    "    #assume senors form a square grid, so take square root of number of sensors\n",
    "    #assume sensors read from middle of domain\n",
    "    n_sense=int(np.sqrt(sensors))\n",
    "    meas=np.empty((n_sense,n_sense))\n",
    "    dimx=domain.shape[0]\n",
    "    dimy=domain.shape[1]\n",
    "    startx=round((dimx-n_sense)/2)\n",
    "    starty=round((dimy-n_sense)/2)\n",
    "    for i in range(n_sense):\n",
    "        for j in range(n_sense):\n",
    "            meas[i,j]=float(domain[i+startx,j+starty])\n",
    "    return meas.flatten()\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(prod(env.action_space.shape) * 2, w_init=jnp.zeros),\n",
    "        hk.Reshape((*env.action_space.shape, 2)),\n",
    "    ))\n",
    "    x = seq(S)\n",
    "    mu, logvar = x[..., 0], x[..., 1]\n",
    "    return {'mu': mu, 'logvar': logvar}\n",
    "\n",
    "\n",
    "def func_q(S, A, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "    ))\n",
    "    X = jnp.concatenate((S, A), axis=-1)\n",
    "    return seq(X)\n",
    "\n",
    "   \n",
    "# main function approximators\n",
    "pi = coax.Policy(func_pi, env)\n",
    "q1 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "q2 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "\n",
    "# target network\n",
    "q1_targ = q1.copy()\n",
    "q2_targ = q2.copy()\n",
    "\n",
    "# experience tracer\n",
    "tracer = coax.reward_tracing.NStep(n=5, gamma=0.9, record_extra_info=True)\n",
    "buffer = coax.experience_replay.SimpleReplayBuffer(capacity=25000)\n",
    "alpha = 0.2\n",
    "policy_regularizer = coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                               beta=alpha / tracer.n,\n",
    "                                                               gamma=tracer.gamma,\n",
    "                                                               n=[tracer.n])\n",
    "\n",
    "# updaters (use current pi to update the q-functions and use sampled action in contrast to TD3)\n",
    "qlearning1 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q1, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "qlearning2 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q2, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "soft_pg = coax.policy_objectives.SoftPG(pi, [q1_targ, q2_targ], optimizer=optax.adam(\n",
    "    1e-3), regularizer=coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                                 beta=alpha / tracer.n,\n",
    "                                                                 gamma=tracer.gamma,\n",
    "                                                                 n=jnp.arange(tracer.n)))\n",
    "\n",
    "#Here define all boundaries to make it easier to add or change controllers\n",
    "#now set up entire array for boundary coordinates.  first row is x coords, second is y coords\n",
    "left_bound=np.full(len(grid.axes_coords[1]), grid.axes_bounds[0][0].item())  #\n",
    "left_bound=np.vstack((left_bound, grid.axes_coords[1]))\n",
    "right_bound=np.full(len(grid.axes_coords[1]), grid.axes_bounds[0][1].item())#\n",
    "right_bound=np.vstack((right_bound, grid.axes_coords[1]))\n",
    "\n",
    "bottom_bound=grid.axes_coords[0]\n",
    "bottom_bound=np.vstack((bottom_bound, np.full(len(bottom_bound), grid.axes_bounds[1][0].item())))\n",
    "top_bound=grid.axes_coords[0]\n",
    "top_bound=np.vstack((top_bound, np.full(len(top_bound), grid.axes_bounds[1][1].item())))\n",
    "\n",
    "#initialize arrays to hold control inputs along each boundary\n",
    "left_control=np.zeros(grid.shape[1])\n",
    "right_control=np.zeros(grid.shape[1])\n",
    "bottom_control=np.zeros(grid.shape[0])\n",
    "top_control=np.zeros(grid.shape[0])\n",
    "\n",
    "#insert controller class initialization\n",
    "actor=controller(grid,state0, Num_sens)\n",
    "\n",
    "tracker=[0.,0.]\n",
    "# train\n",
    "i=0\n",
    "truncated= False\n",
    "while i < 100000:\n",
    "    total_reward=0\n",
    "    actor.state=state0\n",
    "    for t in range(50):#(env.spec.max_episode_steps):\n",
    "        s = sensor_meas(Num_sens, actor.state.data)\n",
    "        #boundary location are input variables into the neural network\n",
    "        #so, for entire control boundary cycle through and call actor network for each point\n",
    "        for j in range(grid.shape[0]):\n",
    "            #hard code going through x and y coor for each boundary location\n",
    "            s_full=jnp.append(s,left_bound[0,j])\n",
    "            s_full=jnp.append(s_full, left_bound[1,j])\n",
    "            a=pi(s_full)\n",
    "            if a>5:  a=np.array([5.0])\n",
    "            elif a<-5:  a=-np.array([5.0])\n",
    "            left_control[j]=a.item()\n",
    "\n",
    "        actor.control=left_control\n",
    "        \n",
    "        s_next, r, done, truncated, info = env.step(actor)\n",
    "        actor.state.data=s_next\n",
    "\n",
    "        #if t % 10 ==0:  print(time.time()-start)\n",
    "        # trace rewards and add transition to replay buffer\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            buffer.add(tracer.pop())\n",
    "\n",
    "        # learn\n",
    "        if len(buffer) >= 5000:\n",
    "            transition_batch = buffer.sample(batch_size=128)\n",
    "\n",
    "            # init metrics dict\n",
    "            metrics = {}\n",
    "\n",
    "            # flip a coin to decide which of the q-functions to update\n",
    "            qlearning = qlearning1 if jax.random.bernoulli(q1.rng) else qlearning2\n",
    "            metrics.update(qlearning.update(transition_batch))\n",
    "\n",
    "            # delayed policy updates\n",
    "            if env.T >= 7500 and env.T % 4 == 0:\n",
    "                metrics.update(soft_pg.update(transition_batch))\n",
    "\n",
    "            env.record_metrics(metrics)\n",
    "\n",
    "            # sync target networks\n",
    "            q1_targ.soft_update(q1, tau=0.001)\n",
    "            q2_targ.soft_update(q2, tau=0.001)\n",
    "        total_reward+=r\n",
    "        if done or truncated:\n",
    "            break\n",
    "\n",
    "    tracker.append([time.time(), total_reward])\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#implement diffusion PDE without gymnasium\n",
    "#I leave in some gymanisum aspects to avoid having to modify func_pi function\n",
    "#I use the gym to define the action space, but reset and step are replaced with direct calls to pde functions\n",
    "\n",
    "import gymnasium\n",
    "import jax\n",
    "import coax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "from numpy import prod\n",
    "import optax\n",
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pde\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import shutup;\n",
    "shutup.please()\n",
    "\n",
    "#geting warning about jax numpy converting float 62 to float 32.  The suggested fix doesn't work, so ignoring\n",
    "\n",
    "\n",
    "from pde import DiffusionPDE, ScalarField, UnitGrid\n",
    "\n",
    "# the name of this script\n",
    "name = 'sac_Diffusion'\n",
    "\n",
    "#define number of sensors and inputs\n",
    "Num_sens=3*3 #size of observation/sensor space in number of grid points\n",
    "grid_dim=2 #x,y for including boundary location in alogrithim\n",
    "Ns=Num_sens+grid_dim #sensors are first in s array, then x,y are last 2 elements\n",
    "\n",
    "#to more easile use existing code for defining and using nns, use gym to define environment\n",
    "#with 1 action space, and Ns dimension observation space, which will help initialize actor\n",
    "env = gymnasium.make('Diffusion-v0', Ns)\n",
    "\n",
    "#define grid and set environment\n",
    "grid = pde.CartesianGrid([[0, 5], [0, 5]], [20, 20], periodic=[False, True]) # generate grid\n",
    "\n",
    "def reward_calc(Num_sens, result):\n",
    "    #reward_calac determines reward from pass sensor measurements based on target\n",
    "    #hard-coded in reward_calc function\n",
    "    target=np.array([[1.,2.,1.],[2.,3.,2.],[1.,2.,1.]])#,[0.5,0.5,0.5]])\n",
    "    #use eucliead norm over n gird points\n",
    "    #first reduce state to sensor points\n",
    "    n_sense=int(np.sqrt(Num_sens))\n",
    "    meas=np.empty((n_sense,n_sense))\n",
    "    dimx=result.data.shape[0]\n",
    "    dimy=result.data.shape[1]\n",
    "    startx=round((dimx-n_sense)/2)\n",
    "    starty=round((dimy-n_sense)/2)\n",
    "    for i in range(n_sense):\n",
    "        for j in range(n_sense):\n",
    "            meas[i,j]=float(result.data[i+startx,j+starty])\n",
    "    reward=(meas-target)**2\n",
    "    reward=1*math.sqrt(np.sum(np.sum(reward)))\n",
    "    return reward\n",
    "\n",
    "#need function to reduce full space to just sensors \n",
    "def sensor_meas(sensors,domain):\n",
    "    #assume senors form a square grid, so take square root of number of sensors\n",
    "    #assume sensors read from middle of domain\n",
    "    n_sense=int(np.sqrt(sensors))\n",
    "    meas=np.empty((n_sense,n_sense))\n",
    "    dimx=domain.shape[0]\n",
    "    dimy=domain.shape[1]\n",
    "    startx=round((dimx-n_sense)/2)\n",
    "    starty=round((dimy-n_sense)/2)\n",
    "    for i in range(n_sense):\n",
    "        for j in range(n_sense):\n",
    "            meas[i,j]=float(domain[i+startx,j+starty])\n",
    "    return meas.flatten()\n",
    "\n",
    "def func_pi(S, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(prod(env.action_space.shape) * 2, w_init=jnp.zeros),\n",
    "        hk.Reshape((*env.action_space.shape, 2)),\n",
    "    ))\n",
    "    x = seq(S)\n",
    "    mu, logvar = x[..., 0], x[..., 1]\n",
    "    return {'mu': mu, 'logvar': logvar}\n",
    "\n",
    "\n",
    "def func_q(S, A, is_training):\n",
    "    seq = hk.Sequential((\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(8), jax.nn.relu,\n",
    "        hk.Linear(1, w_init=jnp.zeros), jnp.ravel\n",
    "    ))\n",
    "    X = jnp.concatenate((S, A), axis=-1)\n",
    "    return seq(X)\n",
    "\n",
    "   \n",
    "# main function approximators\n",
    "pi = coax.Policy(func_pi, env)\n",
    "q1 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "q2 = coax.Q(func_q, env, action_preprocessor=pi.proba_dist.preprocess_variate)\n",
    "\n",
    "# target network\n",
    "q1_targ = q1.copy()\n",
    "q2_targ = q2.copy()\n",
    "\n",
    "# experience tracer\n",
    "tracer = coax.reward_tracing.NStep(n=5, gamma=0.9, record_extra_info=True)\n",
    "buffer = coax.experience_replay.SimpleReplayBuffer(capacity=25000)\n",
    "alpha = 0.2\n",
    "policy_regularizer = coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                               beta=alpha / tracer.n,\n",
    "                                                               gamma=tracer.gamma,\n",
    "                                                               n=[tracer.n])\n",
    "\n",
    "# updaters (use current pi to update the q-functions and use sampled action in contrast to TD3)\n",
    "qlearning1 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q1, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "qlearning2 = coax.td_learning.SoftClippedDoubleQLearning(\n",
    "    q2, pi_targ_list=[pi], q_targ_list=[q1_targ, q2_targ],\n",
    "    loss_function=coax.value_losses.mse, optimizer=optax.adam(1e-3),\n",
    "    policy_regularizer=policy_regularizer)\n",
    "soft_pg = coax.policy_objectives.SoftPG(pi, [q1_targ, q2_targ], optimizer=optax.adam(\n",
    "    1e-3), regularizer=coax.regularizers.NStepEntropyRegularizer(pi,\n",
    "                                                                 beta=alpha / tracer.n,\n",
    "                                                                 gamma=tracer.gamma,\n",
    "                                                                 n=jnp.arange(tracer.n)))\n",
    "\n",
    "#Here define all boundaries to make it easier to add or change controllers\n",
    "#now set up entire array for boundary coordinates.  first row is x coords, second is y coords\n",
    "left_bound=grid.axes_coords[1]\n",
    "left_bound=np.vstack((left_bound, np.full(len(left_bound), grid.axes_bounds[0][0].item())))\n",
    "right_bound=grid.axes_coords[1]\n",
    "right_bound=np.vstack((right_bound, np.full(len(right_bound), grid.axes_bounds[0][1].item())))\n",
    "bottom_bound=grid.axes_coords[0]\n",
    "bottom_bound=np.vstack((bottom_bound, np.full(len(bottom_bound), grid.axes_bounds[1][0].item())))\n",
    "top_bound=grid.axes_coords[0]\n",
    "top_bound=np.vstack((top_bound, np.full(len(top_bound), grid.axes_bounds[1][1].item())))\n",
    "\n",
    "#initialize arrays to hold control inputs along each boundary\n",
    "left_control=np.zeros(grid.shape[1])\n",
    "right_control=np.zeros(grid.shape[1])\n",
    "bottom_control=np.zeros(grid.shape[0])\n",
    "top_control=np.zeros(grid.shape[0])\n",
    "\n",
    "tracker=[0.,0.]\n",
    "# train\n",
    "i=0\n",
    "truncated= False\n",
    "while i < 100000:\n",
    "    total_reward=0\n",
    "    state = ScalarField.random_uniform(grid, 0.0, 0.2)\n",
    "    s = sensor_meas(Num_sens, state.data)\n",
    "    for t in range(50):#(env.spec.max_episode_steps):\n",
    "        #boundary location are input variables into the neural network\n",
    "        #so, for entire control boundary cycle through and call actor network for each point\n",
    "        for j in range(grid.shape[0]):\n",
    "            #hard code going through x and y coor for each boundary location\n",
    "            s_full=jnp.append(s,left_bound[0,j])\n",
    "            s_full=jnp.append(s_full, left_bound[1,j])\n",
    "            a=pi(s_full)\n",
    "            if a>5:  a=np.array([5.0])\n",
    "            elif a<-5:  a=-np.array([5.0])\n",
    "            left_control[j]=a.item()\n",
    "        bc_x_right={\"value\": 0}\n",
    "        bc_x_left={\"value\": left_control}\n",
    "        bc_x=[bc_x_left, bc_x_right]\n",
    "        bc_y=\"periodic\"\n",
    "        #s_next, r, done, truncated, info = env.step(a)\n",
    "        start=time.time()\n",
    "        eq = DiffusionPDE(diffusivity=0.5, bc=[bc_x, bc_y])\n",
    "        result = eq.solve(state, t_range=0.2, adaptive=True, tracker=None)\n",
    "        s_next=result.data\n",
    "        \n",
    "        r=reward_calc(Num_sens, result)\n",
    "        if t<50:  done=False\n",
    "        if t % 10 ==0:  print(time.time()-start)\n",
    "        # trace rewards and add transition to replay buffer\n",
    "        tracer.add(s, a, r, done)\n",
    "        while tracer:\n",
    "            buffer.add(tracer.pop())\n",
    "\n",
    "        # learn\n",
    "        if len(buffer) >= 5000:\n",
    "            transition_batch = buffer.sample(batch_size=128)\n",
    "\n",
    "            # init metrics dict\n",
    "            metrics = {}\n",
    "\n",
    "            # flip a coin to decide which of the q-functions to update\n",
    "            qlearning = qlearning1 if jax.random.bernoulli(q1.rng) else qlearning2\n",
    "            metrics.update(qlearning.update(transition_batch))\n",
    "\n",
    "            # delayed policy updates\n",
    "            if env.T >= 10 and env.T % 4 == 0:\n",
    "                metrics.update(soft_pg.update(transition_batch))\n",
    "                print(r, i)\n",
    "\n",
    "            env.record_metrics(metrics)\n",
    "\n",
    "            # sync target networks\n",
    "            q1_targ.soft_update(q1, tau=0.001)\n",
    "            q2_targ.soft_update(q2, tau=0.001)\n",
    "        total_reward+=r\n",
    "        if done or truncated:\n",
    "            break\n",
    "        state=result\n",
    "        s = sensor_meas(Num_sens,s_next)\n",
    "    tracker.append([time.time(), total_reward])\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
